{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _DATATYPE = _descriptor.EnumDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORPROTO = _descriptor.Descriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:46: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import gym_donkeycar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import time\n",
    "import pickle\n",
    "import birds_eye_vector_space\n",
    "import random\n",
    "from pandas import Series, DataFrame\n",
    "from collections import deque\n",
    "\n",
    "#from keras.layers import Dense\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#from keras.initializers import normal, identity\n",
    "#from keras.models import model_from_json\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "#from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.client import device_lib\n",
    "#from keras import backend as K\n",
    "#import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 16979976778990274064\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 258277376\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 13552242279705086397\n",
       " physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:49:00.0, compute capability: 7.5\"\n",
       " xla_global_id: 416903419,\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6271991808\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3164994792808137784\n",
       " physical_device_desc: \"device: 1, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5\"\n",
       " xla_global_id: 2144165316]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress scientific notation like: e*+03\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_POINTS = 8\n",
    "ROAD_ROI = np.array([(120,90),(200,90),(0,200),(320,200)],dtype='float32')\n",
    "WARPED_IMAGE_SHAPE = np.array([[10,320],[0,0],[200,0],[200,310]],np.int32)            # NEW IMAGE Shape after Warping !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "WARPED_IMAGE_HEIGHT = 320\n",
    "WARPED_IMAGE_WIDTH = 200\n",
    "NUMBER_OF_DEPTH_LAYERS = 50\n",
    "\n",
    "VECTOR_SPACE_IMAGE_ROWS = 50\n",
    "VECTOR_SPACE_IMAGE_COLUMNS = 100\n",
    "VECTOR_SPACE_IMAGE_CHANNELS = 4 # 4*(50,100) stacked frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save the plots\n",
    "def save_plot(data, name, episode):\n",
    "    plt.figure(figsize=(8,5), frameon=True)\n",
    "    #plt.plot([episode for episode in range(len(data))], data)\n",
    "    plt.plot([ep for ep in range(episode)], data)\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel(name)\n",
    "    figplot = '%s-episode-%s.png' % (name,episode)\n",
    "    #figplot = '{}-episode-{}.png'.format(name,episode)\n",
    "    #location = '{}/saves/torch/{}'.format(os.getcwd(),figplot)\n",
    "    #location = '%s/collected_data/plots/%s' % (os.getcwd(),figplot)\n",
    "    location = 'C:\\\\Users\\\\studwilksa2535\\\\Desktop\\\\DonkeyCarAI\\\\collected_data\\\\plots\\\\%s' % figplot \n",
    "    plt.savefig(location, transparent=False)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_as_dataframe(episode_number, reward, loss, measured_time, max_cte, average_cte, last_lap_time):\n",
    "    episodes = [i for i in range(1, episode_number+1)]\n",
    "    collected_data = {'episode': episodes, 'reward': reward, 'loss':loss, 'time': measured_time, 'max_cte': max_cte, 'average_cte': average_cte, 'lap_time': last_lap_time}\n",
    "    df_data = DataFrame.from_dict(collected_data).set_index('episode')\n",
    "    \n",
    "    df_name = 'data-episode-%s.pkl' % episode\n",
    "    #location = '%s/collected_data/raw_data/%s' % (os.getcwd(),df_name)\n",
    "    location = 'C:\\\\Users\\\\studwilksa2535\\\\Desktop\\\\DonkeyCarAI\\\\collected_data\\\\raw_data\\\\%s' % df_name\n",
    "    df_data.to_pickle(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector space is initialized\n",
      "loading camera parameters\n"
     ]
    }
   ],
   "source": [
    "vector_space = birds_eye_vector_space.Vector_space(ANCHOR_POINTS, ROAD_ROI, WARPED_IMAGE_SHAPE, WARPED_IMAGE_HEIGHT, WARPED_IMAGE_WIDTH, NUMBER_OF_DEPTH_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\studwilksa2535\\\\Desktop\\\\DonkeyCarAI\\\\Master-Thesis-Development-of-a-Deep-RL-Model-for-simulated-Driving-2D-Vector-Space\\\\docker\\\\src'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.t = 0\n",
    "        self.max_Q = 0\n",
    "        self.train = True\n",
    "        # Set to True to train on images with segmented lane lines\n",
    "        self.lane_detection = False\n",
    "        \n",
    "        # Huber loss\n",
    "        self.huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "        \n",
    "        # Get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        # CNN Input\n",
    "        #self.input_shape = (VECTOR_SPACE_IMAGE_CHANNELS, VECTOR_SPACE_IMAGE_ROWS, VECTOR_SPACE_IMAGE_COLUMNS, 4)   # == 4 * (50, 100, 1); keras: (1,50,100,4)\n",
    "        self.input_shape = (1, VECTOR_SPACE_IMAGE_ROWS, VECTOR_SPACE_IMAGE_COLUMNS, VECTOR_SPACE_IMAGE_CHANNELS)   # == 4 * (50, 100, 1); keras: (1,50,100,4)\n",
    "        \n",
    "        # These are hyper parameters for the DQN\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 1e-4\n",
    "        if (self.train):\n",
    "            self.epsilon = 1.0\n",
    "            self.initial_epsilon = 1.0\n",
    "        else:\n",
    "            self.epsilon = 1e-6\n",
    "            self.initial_epsilon = 1e-6\n",
    "        self.epsilon_min = 0.02\n",
    "        self.batch_size = 512\n",
    "        self.train_start = 100\n",
    "        self.explore = 10000\n",
    "        \n",
    "        # Create replay memory using deque\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        \n",
    "        # Create main model and target model                # Double DQN !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "\n",
    "        # Copy the model to target model\n",
    "        # --> initialize the target model so that the parameters of model & target model to be same\n",
    "        self.update_target_model()\n",
    "        \n",
    "    def build_model_old(self):\n",
    "        print('delte this')\n",
    "        #model = Sequential()\n",
    "        #model.add(Convolution2D(32, 8, 8, subsample=(4, 4), border_mode='same',input_shape=(VECTOR_SPACE_IMAGE_ROWS,VECTOR_SPACE_IMAGE_COLUMNS,VECTOR_SPACE_IMAGE_CHANNELS)))  #80*80*4\n",
    "        #model.add(Activation('relu'))\n",
    "        #model.add(Convolution2D(64, 4, 4, subsample=(2, 2), border_mode='same'))\n",
    "        #model.add(Activation('relu'))\n",
    "        #model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode='same'))\n",
    "        #model.add(Activation('relu'))\n",
    "        #model.add(Flatten())\n",
    "        #model.add(Dense(512))\n",
    "        #model.add(Activation('relu'))\n",
    "\n",
    "        ## 15 categorical bins for Steering angles\n",
    "        #model.add(Dense(15, activation=\"linear\")) \n",
    "\n",
    "        #adam = Adam(lr=self.learning_rate)\n",
    "        #model.compile(loss='mse',optimizer=adam)\n",
    "\n",
    "        #return model\n",
    "\n",
    "    def build_model(self):\n",
    "        model = keras.Sequential([\n",
    "            layers.Conv2D(filters=32, strides=(4, 4),kernel_size=8, padding='same', activation='relu', input_shape=(self.input_shape[1:])),\n",
    "            layers.Conv2D(filters=64, strides=(2, 2),kernel_size=4, padding='same', activation='relu'),\n",
    "            layers.Conv2D(filters=64, strides=(1, 1),kernel_size=3, padding='same', activation='relu'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(units=512,activation='relu'),\n",
    "            layers.Dense(units=15,activation='linear'),\n",
    "        ])\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        model.compile(loss='mse', optimizer=optimizer)\n",
    "        return model\n",
    "    \n",
    "    def calculate_loss(self, y_true, y_pred):    \n",
    "        y_pred = tf.convert_to_tensor_v2(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        return tf.reduce_mean(math_ops.square(y_pred - y_true), axis=-1)\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    # Get action from model using epsilon-greedy policy\n",
    "    def get_action(self, s_t):\n",
    "        #if np.random.rand() <= self.epsilon:\n",
    "        #    #print(\"Return Random Value\")\n",
    "        #    #return random.randrange(self.action_size)\n",
    "        #    return np.random.uniform(-1,1)\n",
    "        #else:\n",
    "        #    #print(\"Return Max Q Prediction\")\n",
    "        #    q_value = self.model.predict(s_t)\n",
    "        #    # Convert q array to steering value\n",
    "        #    return linear_unbin(q_value[0])\n",
    "        q_value = self.model.predict(s_t)\n",
    "        # Convert q array to steering value\n",
    "        return linear_unbin(q_value[0])\n",
    "\n",
    "    def replay_memory(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        #if self.epsilon > self.epsilon_min:\n",
    "        #    #self.epsilon *= self.epsilon_decay\n",
    "        #    self.epsilon -= (self.initial_epsilon - self.epsilon_min) / self.explore\n",
    "\n",
    "    def train_replay(self):\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        \n",
    "        # Epsilion decay over time/amount of trainings\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            #self.epsilon *= self.epsilon_decay\n",
    "            #self.epsilon -= (self.initial_epsilon - self.epsilon_min) / self.explore\n",
    "            self.epsilon -= 0.00025\n",
    "            \n",
    "        batch_size = min(self.batch_size, len(self.memory))\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        state_t, action_t, reward_t, state_t1, terminal = zip(*minibatch)\n",
    "        #print('Starting training\\nstate_t: %s\\naction_t: %s\\nreward_t: %s\\nstate_1: %s\\nterminal: %s' % (len(state_t), len(action_t), len(reward_t), len(state_t1), len(terminal)))\n",
    "        state_t = np.concatenate(state_t)\n",
    "        state_t1 = np.concatenate(state_t1)\n",
    "        #print('Concat:\\nstate: %s\\nstate_t1: %s' % (state_t, state_t1))\n",
    "        targets = self.model.predict(state_t)\n",
    "        self.max_Q = np.max(targets[0])\n",
    "        target_val = self.model.predict(state_t1)\n",
    "        target_val_ = self.target_model.predict(state_t1)\n",
    "        for i in range(batch_size):\n",
    "            if terminal[i]:\n",
    "                targets[i][action_t[i]] = reward_t[i]\n",
    "            else:\n",
    "                a = np.argmax(target_val[i])\n",
    "                targets[i][action_t[i]] = reward_t[i] + self.discount_factor * (target_val_[i][a])\n",
    "\n",
    "        \n",
    "        # train on the current batch and return a dictionary with the loss and so on\n",
    "        #metrics = self.model.train_on_batch(x=state_t, y=targets, reset_metrics=True, return_dict=True)           \n",
    "        metrics = self.model.train_on_batch(x=state_t, y=targets, reset_metrics=False, return_dict=True) #reset Metrix different\n",
    "        return metrics['loss']\n",
    "        \n",
    "    def load_model(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    # Save the model which is under training\n",
    "    def save_model(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_bin(a):\n",
    "    \"\"\"\n",
    "    Convert a value to a categorical array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : int or float\n",
    "        A value between -1 and 1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of int\n",
    "        A list of length 15 with one item set to 1, which represents the linear value, and all other items set to 0.\n",
    "    \"\"\"\n",
    "    a = a + 1\n",
    "    b = round(a / (2 / 14))\n",
    "    arr = np.zeros(15)\n",
    "    arr[int(b)] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_unbin(arr):\n",
    "    \"\"\"\n",
    "    Convert a categorical array to value.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    linear_bin\n",
    "    \"\"\"\n",
    "    if not len(arr) == 15:\n",
    "        raise ValueError('Illegal array length, must be 15')\n",
    "    b = np.argmax(arr)\n",
    "    a = b * (2 / 14) - 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.core.client:connecting to localhost:9091 \n",
      "C:\\Users\\studwilksa2535\\AppData\\Roaming\\Python\\Python38\\site-packages\\gym\\spaces\\box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "WARNING:gym_donkeycar.envs.donkey_sim:waiting for sim to start..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting DonkeyGym env\n",
      "Setting default: start_delay 5.0\n",
      "Setting default: max_cte 5.0\n",
      "Setting default: frame_skip 1\n",
      "Setting default: cam_resolution (120, 160, 3)\n",
      "Setting default: log_level 20\n",
      "Setting default: host localhost\n",
      "Setting default: port 9091\n",
      "loading scene generated_track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_donkeycar.envs.donkey_sim:on need car config\n",
      "INFO:gym_donkeycar.envs.donkey_sim:sending car config.\n",
      "INFO:gym_donkeycar.envs.donkey_sim:done sending cam config. {'img_w': '320', 'img_h': '200', 'img_d': '1', 'img_enc': 'PNG', 'fov': '90', 'fish_eye_x': '0.0', 'fish_eye_y': '0.0', 'offset_x': '0.0', 'offset_y': '0.0', 'offset_z': '0.0', 'rot_x': '0'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE: 1 | TIME: 26.84152126312256 s | REWARD: 1.9751761588342587 | FRAMES: 178 | QMAX: 0 | EPSILON: 1.0 | CTE: -2.4719454423033724 | LOSS: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 63>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    139\u001b[0m cv\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvec img\u001b[39m\u001b[38;5;124m'\u001b[39m, next_observation_show)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Graykonvertion of the observation image\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m#observation = cv.cvtColor(observation, cv.COLOR_BGR2GRAY)\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m#break       # TODO: DELTE LATER\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    153\u001b[0m     cv\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%% SET UP ENVIRONMENT\n",
    "# Normal one \n",
    "#os.environ['DONKEY_SIM_PATH'] = \"/home/zamy/masterthesis/DonkeySimLinux/donkey_sim.x86_64\"\n",
    "os.environ['DONKEY_SIM_PATH'] = \"C:\\\\Users\\\\studwilksa2535\\\\Desktop\\\\DonkeyCarAI\\\\test\\\\DonkeySimWin\\\\donkey_sim.exe\"\n",
    "os.environ['DONKEY_SIM_PORT'] = str(9091)\n",
    "os.environ['DONKEY_SIM_HEADLESS'] = str(0) # \"1\" is headless\n",
    "\n",
    "CAMERA_CONF = {'cam_config':{'img_w': '320',\n",
    "                        'img_h': '200',\n",
    "                        'img_d': '1',   # 3 for colored Tensor image\n",
    "                        'img_enc': 'PNG', \n",
    "                        'fov': '90', \n",
    "                        'fish_eye_x': '0.0', \n",
    "                        'fish_eye_y': '0.0', \n",
    "                        'offset_x': '0.0', \n",
    "                        'offset_y': '0.0', \n",
    "                        'offset_z': '0.0', \n",
    "                        'rot_x': '0'}}\n",
    "# Other tracks\n",
    "#env = gym.make(\"donkey-generated-track-v0\",conf=CAMERA_CONF)\n",
    "\n",
    "# TRACKS TRACKS - TKarmer Tracks\n",
    "#env = gym.make(\"donkey-generated-track-v0\",conf=CAMERA_CONF) #,conf=config\n",
    "# Random track, but the reward is kinda not working, IF THE REWARD WORKS IT IS KINDA RANDOM !!, this maybe debends on the environment\n",
    "env = gym.make(\"donkey-generated-roads-v0\",conf=CAMERA_CONF) #,conf=config\n",
    "\n",
    "# Mini Monaco Track\n",
    "#env = gym.make(\"donkey-minimonaco-track-v0\",conf=CAMERA_CONF) #,conf=config\n",
    "#env = gym.make(\"donkey-generated-track-v0\") #,conf=config\n",
    "#env = gym.wrappers.ResizeObservation(env,(200,320))\n",
    "\n",
    "## DELETE LATER\n",
    "#env.frameskip = 1\n",
    "#gym.wrappers.max\n",
    "\n",
    "# Create DQN Model\n",
    "# Get size of state and action from environment\n",
    "state_size = (VECTOR_SPACE_IMAGE_ROWS, VECTOR_SPACE_IMAGE_COLUMNS, VECTOR_SPACE_IMAGE_CHANNELS)\n",
    "action_size = 15 # Steering and Throttle\n",
    "throttle = 0.15 # Set the throttle as a constant value\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "# loading the latest model\n",
    "#agent.load_model('C:\\\\Users\\\\studwilksa2535\\\\Desktop\\\\DonkeyCarAI\\\\models\\\\model_episode_5000.h5')\n",
    "#agent.load_model('C:\\\\Users\\\\studwilksa2535\\\\Desktop\\\\DonkeyCarAI\\\\models\\\\model_episode_10000.h5')\n",
    "agent.load_model('C:\\\\Users\\\\studwilksa2535\\\\Desktop\\\\DonkeyCarAI\\\\models\\\\model_episode_1400.h5')\n",
    "\n",
    "#first model that kinda works\n",
    "#agent.load_model('C:\\\\Users\\\\studwilksa2535\\\\Desktop\\\\DonkeyCarAI\\\\old_model\\\\model_episode_5000.h5')\n",
    "\n",
    "# Arrays for data collection / exploratory data analysis\n",
    "average_cte = []\n",
    "average_speed = []\n",
    "measured_time = []\n",
    "average_rewards = []\n",
    "average_loss = []\n",
    "collected_max_cte = []\n",
    "collected_lap_time = []\n",
    "\n",
    "# when a model and the data should be saved\n",
    "save_state = 200\n",
    "\n",
    "for episode in range(1,5):\n",
    "    # Resetting the environment and preprocessing the first image\n",
    "    observation = env.reset()\n",
    "    # Graykonvertion of the observation image\n",
    "    observation = cv.cvtColor(observation, cv.COLOR_BGR2GRAY)\n",
    "    observation = vector_space.image_preprocessing(observation)\n",
    "    # frame stacking (4 times)\n",
    "    obv_stack = np.stack((observation, observation, observation, observation), axis= 2)\n",
    "    # reshaping for keras\n",
    "    obv_stack = obv_stack.reshape(1, obv_stack.shape[0], obv_stack.shape[1], obv_stack.shape[2])\n",
    "    \n",
    "    #action = np.array([0,0.10]) # drive straight with small speed\n",
    "    #action = np.array([1,0.1]) # drive straight with small speed\n",
    "    \n",
    "    # summed up values for data collection\n",
    "    # cumulative values for data collection\n",
    "    total_cte = float(0)\n",
    "    total_speed = float(0)\n",
    "    total_reward = float(0)\n",
    "    total_time = time.time()\n",
    "    total_loss = float(0)\n",
    "    max_cte = int(0)\n",
    "    lap_time = int(0)\n",
    "        \n",
    "    # counting the amount of frames per episode\n",
    "    frames = int(0)\n",
    "    \n",
    "    # boolean that describes if the env is done with this episode\n",
    "    done = False\n",
    "    while not done:\n",
    "        # incrementing the amount of frames per episode\n",
    "        frames += 1\n",
    "        \n",
    "        # Making a prediction for the current state\n",
    "        # and getting the information form the next step\n",
    "        steering = agent.get_action(obv_stack)\n",
    "        action = [steering, throttle]\n",
    "        next_observation, reward, done, info = env.step(action)\n",
    "        # Graykonvertion of the observation image\n",
    "        next_observation = cv.cvtColor(next_observation, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # preprocessing the new observation\n",
    "        next_observation_show = vector_space.image_preprocessing(next_observation)\n",
    "        # reshaping for keras\n",
    "        #next_observation = next_observation_show.reshape(1, next_observation_show.shape[0], next_observation_show.shape[1], 1)\n",
    "        # appending to the observation stack\n",
    "        #obv_stack = np.append(next_observation, obv_stack[:, :, :, :3], axis=3)\n",
    "        \n",
    "        obv_stack_t1 = np.stack([next_observation_show, obv_stack[0,:,:,0],obv_stack[0,:,:,1],obv_stack[0,:,:,2]], axis=2)\n",
    "        obv_stack_t1 = obv_stack_t1.reshape(1, obv_stack_t1.shape[0], obv_stack_t1.shape[1], obv_stack_t1.shape[2])\n",
    "                \n",
    "        # saving the sample <s, a, r, s'> to the replay memory\n",
    "        #agent.replay_memory(obv_stack, np.argmax(linear_bin(steering)), reward, obv_stack_t1, done)        \n",
    "        \n",
    "        # training the DDQN, if training is enabled\n",
    "        #if agent.train:\n",
    "        #    loss = agent.train_replay()\n",
    "        #    if loss != None:\n",
    "        #        total_loss += loss\n",
    "        #        #print('loss: %s ' % (total_loss / frames))\n",
    "        \n",
    "        # overwriting the stack and incrementing the time/frame counter\n",
    "        obv_stack = obv_stack_t1\n",
    "        agent.t += 1       \n",
    "        \n",
    "        # adding up the collected data\n",
    "        current_cte = info['cte'] \n",
    "        total_cte += current_cte\n",
    "        total_speed += info['speed']\n",
    "        total_reward += reward\n",
    "        # update if there is any change in incrementation \n",
    "        if max_cte < current_cte:\n",
    "            max_cte = current_cte\n",
    "        if lap_time < info['last_lap_time']:\n",
    "            lap_time = info['last_lap_time']\n",
    "            \n",
    "        cv.imshow('vec img', next_observation_show)\n",
    "\n",
    "        # Graykonvertion of the observation image\n",
    "        #observation = cv.cvtColor(observation, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Image preprocessing\n",
    "        #vec_image = vector_space.image_preprocessing(observation)\n",
    "        \n",
    "        #print('REWARD: %s' % reward)\n",
    "        \n",
    "        #cv.imshow('vec img', vec_image)\n",
    "        \n",
    "        #break       # TODO: DELTE LATER\n",
    "        if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "            cv.destroyAllWindows()\n",
    "            break\n",
    "    \n",
    "    # Training after each episode\n",
    "    #if agent.train:    \n",
    "    #    total_loss = agent.train_replay()\n",
    "    #    #if loss != None:\n",
    "    #    #    total_loss = loss\n",
    "    \n",
    "    \n",
    "    # AFTER this Episode & the environment returns True for the done variable\n",
    "    # updating the target DDQN\n",
    "    #agent.update_target_model()\n",
    "    \n",
    "    # calculating the average loss in this episode\n",
    "    #episode_loss = total_loss.copy() #/ frames\n",
    "    episode_cte = total_cte / frames\n",
    "    episode_reward = total_reward / frames\n",
    "    \n",
    "    # updating the time parameter\n",
    "    total_time = abs(total_time - time.time())\n",
    "    \n",
    "    # appending the collected data\n",
    "    average_cte.append(episode_cte)\n",
    "    average_speed.append(total_speed / frames)\n",
    "    measured_time.append(total_time)\n",
    "    average_rewards.append(episode_reward)\n",
    "    average_loss.append(total_loss)\n",
    "    collected_max_cte.append(max_cte)\n",
    "    collected_lap_time.append(lap_time) \n",
    "    \n",
    "    # Testing of saving the plot\n",
    "    #if episode % 3 == 0 and episode != 0:\n",
    "    #    save_plot(colleted_rewards, 'Reward', episode)\n",
    "    #    cv.destroyAllWindows()\n",
    "    #    break\n",
    "    \n",
    "    # Print episode information    \n",
    "    print('EPISODE: %s | TIME: %s s | REWARD: %s | FRAMES: %s | QMAX: %s | EPSILON: %s | CTE: %s | LOSS: %s' % (episode, total_time, episode_reward, frames, str(agent.max_Q), agent.epsilon, episode_cte, total_loss))    \n",
    "    \n",
    "    if episode % save_state == 0 and episode != 0:\n",
    "        print('saving after %s episodes' % save_state)\n",
    "        # saving the model\n",
    "        agent.save_model('C:\\\\Users\\\\studwilksa2535\\\\Desktop\\\\DonkeyCarAI\\\\models\\\\model_episode_%s.h5' % episode)        \n",
    "        \n",
    "        # Saving the data as plots\n",
    "        save_plot(average_rewards, 'Reward', episode)\n",
    "        save_plot(average_cte, 'Average cte', episode)\n",
    "        save_plot(collected_max_cte, 'Max cte', episode)\n",
    "        save_plot(measured_time, 'Time', episode)\n",
    "        save_plot(average_loss, 'Loss', episode)\n",
    "        save_plot(collected_lap_time, 'Lap Time', episode)\n",
    "        \n",
    "        # Saving the collected data\n",
    "        save_data_as_dataframe(episode, average_rewards, average_loss, measured_time, collected_max_cte, average_cte, collected_lap_time)\n",
    "    \n",
    "    # closing all cv windows\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "# closing all cv windows\n",
    "cv.destroyAllWindows()\n",
    "# Close the enviroment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
